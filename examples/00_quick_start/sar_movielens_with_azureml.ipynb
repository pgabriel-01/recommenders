{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SAR on MovieLens with Azure Machine Learning (Python, CPU)\n",
    "---\n",
    "## Introduction to Azure Machine Learning  \n",
    "The **[Azure Machine Learning service (AzureML)](https://docs.microsoft.com/azure/machine-learning/service/overview-what-is-azure-ml)** provides a cloud-based environment you can use to prep data, train, test, deploy, manage, and track machine learning models. By using Azure Machine Learning service, you can start training on your local machine and then scale out to the cloud. With many available compute targets, like [Azure Machine Learning Compute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) and [Azure Databricks](https://docs.microsoft.com/en-us/azure/azure-databricks/what-is-azure-databricks), and with [advanced hyperparameter tuning services](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters), you can build better models faster by using the power of the cloud.\n",
    "\n",
    "Data scientists and AI developers use the main [Azure Machine Learning Python SDK](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py) to build and run machine learning workflows with the Azure Machine Learning service. You can interact with the service in any Python environment, including Jupyter Notebooks or your favorite Python IDE. The Azure Machine Learning SDK allows you the choice of using local or cloud compute resources, while managing and maintaining the complete data science workflow from the cloud.\n",
    "![AzureML Workflow](https://docs.microsoft.com/en-us/azure/machine-learning/service/media/overview-what-is-azure-ml/aml.png)\n",
    "\n",
    "This notebook provides an example of how to utilize and evaluate the Simple Algorithm for Recommendation (SAR) algorithm using the Azure Machine Learning service. It takes the content of the [SAR quickstart notebook](sar_movielens.ipynb) and demonstrates how to use the power of the cloud to manage data, switch to powerful GPU machines, and monitor runs while training a model. \n",
    "\n",
    "See the hyperparameter tuning notebook for more advanced use cases with AzureML.\n",
    "\n",
    "### Advantages of using AzureML:\n",
    "- Manage cloud resources for monitoring, logging, and organizing your machine learning experiments.\n",
    "- Train models either locally or by using cloud resources, including GPU-accelerated model training.\n",
    "- Easy to scale out when dataset grows - by just creating and pointing to new compute target\n",
    "\n",
    "---\n",
    "## Details of SAR\n",
    "<details>\n",
    "    <summary>Click to expand</summary>\n",
    "    \n",
    "SAR is a fast scalable adaptive algorithm for personalized recommendations based on user transaction history. It produces easily explainable / interpretable recommendations and handles \"cold item\" and \"semi-cold user\" scenarios. SAR is a kind of neighborhood based algorithm (as discussed in [Recommender Systems by Aggarwal](https://dl.acm.org/citation.cfm?id=2931100)) which is intended for ranking top items for each user. \n",
    "\n",
    "SAR recommends items that are most ***similar*** to the ones that the user already has an existing ***affinity*** for. Two items are ***similar*** if the users who have interacted with one item are also likely to have interacted with another. A user has an ***affinity*** to an item if they have interacted with it in the past.\n",
    "\n",
    "### Advantages of SAR:\n",
    "- High accuracy for an easy to train and deploy algorithm\n",
    "- Fast training, only requiring simple counting to construct matrices used at prediction time\n",
    "- Fast scoring, only involving multiplication of the similarity matric with an affinity vector\n",
    "\n",
    "### Notes to use SAR properly:\n",
    "- SAR does not use item or user features, so cannot handle cold-start use cases\n",
    "- SAR requires the creation of an $mxm$ dense matrix (where $m$ is the number of items). So memory consumption can be an issue with large numbers of items.\n",
    "- SAR is best used for ranking items per user, as the scale of predicted ratings may be different from the input range and will differ across users.\n",
    "For more details see the deep dive notebook on SAR here: [SAR Deep Dive Notebook](../02_model_collaborative_filtering/sar_deep_dive.ipynb)</details>\n",
    "---\n",
    "## Prerequisities\n",
    "   - **Azure Subscription**\n",
    "     - If you don’t have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning service today](https://azure.microsoft.com/en-us/free/services/machine-learning/).\n",
    "     - You get credits to spend on Azure services, which will easily cover the cost of running this example notebook. After they're used up, you can keep the account and use [free Azure services](https://azure.microsoft.com/en-us/free/). Your credit card is never charged unless you explicitly change your settings and ask to be charged. Or [activate MSDN subscriber benefits](https://azure.microsoft.com/en-us/pricing/member-offers/credit-for-visual-studio-subscribers/), which give you credits every month that you can use for paid Azure services.\n",
    "---   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.45.0\n",
      "MLflow version: 1.28.0\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from recommenders.datasets import movielens\n",
    "import mlflow\n",
    "import mlflow.azureml\n",
    "\n",
    "print(\"azureml.core version: {}\".format(azureml.core.VERSION))\n",
    "print(\"MLflow version:\", mlflow.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to an AzureML workspace\n",
    "\n",
    "An [AzureML Workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py) is an Azure resource that organizes and coordinates the actions of many other Azure resources to assist in executing and sharing machine learning workflows. In particular, an Azure ML Workspace coordinates storage, databases, and compute resources providing added functionality for machine learning experimentation, deployment, inferencing, and the monitoring of deployed models.\n",
    "\n",
    "The function below will get or create an AzureML Workspace and save the configuration to `aml_config/config.json`.\n",
    "\n",
    "It defaults to use provided input parameters or environment variables for the Workspace configuration values. Otherwise, it will use an existing configuration file (either at `./aml_config/config.json` or a path specified by the config_path parameter).\n",
    "\n",
    "Lastly, if the workspace does not exist, one will be created for you. See [this tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace#portal) to locate information such as subscription id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Temporary Directory\n",
    "This directory will house the data and scripts needed by the AzureML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset and upload to datastore\n",
    "\n",
    "Every workspace comes with a default [datastore](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data) (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and access it from the compute target.\n",
    "\n",
    "The data files are uploaded into a directory named `data` at the root of the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.81k/4.81k [00:00<00:00, 37.7kKB/s]\n",
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_0ff263a8ec594374a493b167a5845c43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_DIR = 'movielens'\n",
    "\n",
    "# download dataset\n",
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['UserId','MovieId','Rating','Timestamp']\n",
    ")\n",
    "\n",
    "# upload dataset to workspace datastore\n",
    "data_file_name = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_data.pkl\"\n",
    "data.to_pickle(os.path.join(tmp_dir.name, data_file_name))\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir=tmp_dir.name, target_path=TARGET_DIR, overwrite=True, show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach Azure Machine Learning Compute \n",
    "\n",
    "We create a cpu cluster as our **remote compute target**. If a cluster with the same name already exists in your workspace, the script will load it instead. You can read [Set up compute targets for model training](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets) to learn more about setting up compute target on different locations. You can also create GPU machines when larger machines are necessary to train the model.\n",
    "\n",
    "According to Azure [Pricing calculator](https://azure.microsoft.com/en-us/pricing/calculator/), with example VM size `STANDARD_D2_V2`, it costs a few dollars to run this notebook, which is well covered by Azure new subscription credit. For billing and pricing questions, please contact [Azure support](https://azure.microsoft.com/en-us/support/options/).\n",
    "\n",
    "**Note**:\n",
    "- 10m and 20m dataset requires more capacity than `STANDARD_D2_V2`, such as `STANDARD_NC6` or `STANDARD_NC12`. See list of all available VM sizes [here](https://docs.microsoft.com/en-us/azure/templates/Microsoft.Compute/2018-10-01/virtualMachines?toc=%2Fen-us%2Fazure%2Fazure-resource-manager%2Ftoc.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json#hardwareprofile-object).\n",
    "- As with other Azure services, there are limits on certain resources (e.g. AzureML Compute quota) associated with the Azure Machine Learning service. Please read [these instructions](https://docs.microsoft.com/en-us/azure/azure-supportability/resource-manager-core-quotas-request) on the default limits and how to request more quota.\n",
    "---\n",
    "#### Learn more about Azure Machine Learning Compute\n",
    "<details>\n",
    "    <summary>Click to learn more about compute types</summary>\n",
    "    \n",
    "[Azure Machine Learning Compute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) is managed compute infrastructure that allows the user to easily create single to multi-node compute of the appropriate VM Family. It is created within your workspace region and is a resource that can be used by other users in your workspace. It autoscales by default to the max_nodes, when a job is submitted, and executes in a containerized environment packaging the dependencies as specified by the user.\n",
    "\n",
    "Since it is managed compute, job scheduling and cluster management are handled internally by Azure Machine Learning service.\n",
    "\n",
    "You can provision a persistent AzureML Compute resource by simply defining two parameters thanks to smart defaults. By default it autoscales from 0 nodes and provisions dedicated VMs to run your job in a container. This is useful when you want to continously re-use the same target, debug it between jobs or simply share the resource with other users of your workspace.\n",
    "\n",
    "In addition to vm_size and max_nodes, you can specify:\n",
    "- **min_nodes**: Minimum nodes (default 0 nodes) to downscale to while running a job on AzureML Compute\n",
    "- **vm_priority**: Choose between 'dedicated' (default) and 'lowpriority' VMs when provisioning AzureML Compute. Low Priority VMs use Azure's excess capacity and are thus cheaper but risk your run being pre-empted\n",
    "- **idle_seconds_before_scaledown**: Idle time (default 120 seconds) to wait after run completion before auto-scaling to min_nodes\n",
    "- **vnet_resourcegroup_name**: Resource group of the existing VNet within which Azure MLCompute should be provisioned\n",
    "- **vnet_name**: Name of VNet\n",
    "- **subnet_name**: Name of SubNet within the VNet\n",
    "</details>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "source": [
    "# Remote compute (cluster) configuration. If you want to save the cost more, set these to small.\n",
    "VM_SIZE = 'STANDARD_D2_V2'\n",
    "# Cluster nodes\n",
    "MIN_NODES = 0\n",
    "MAX_NODES = 2\n",
    "\n",
    "CLUSTER_NAME = 'cpu-cluster'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "    print(\"Found existing compute target\")\n",
    "except:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=VM_SIZE,\n",
    "        min_nodes=MIN_NODES,\n",
    "        max_nodes=MAX_NODES\n",
    "    )\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training script\n",
    "### 1. Create a directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.path.join(tmp_dir.name, 'movielens-sar')\n",
    "os.makedirs(SCRIPT_DIR, exist_ok=True)\n",
    "TRAIN_FILE = os.path.join(SCRIPT_DIR, 'train.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a training script\n",
    "To submit the job to the cluster, first create a training script. Run the following code to create the training script called `train.py` in temporary directory. This training adds a regularization rate to the training algorithm, so produces a slightly different model than the local version.\n",
    "\n",
    "This code takes what is in the local quickstart and convert it to one single training script. We use run.log() to record parameters to the run. We will be able to review and compare these measures in the Azure Portal at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/tmpemvzlzed/movielens-sar/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAIN_FILE\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "from azureml.core import Run\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.azureml\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.models.sar import SAR\n",
    "\n",
    "mlflow.autolog()\n",
    "TOP_K = 10\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "\n",
    "TARGET_DIR = 'movielens'\n",
    "OUTPUT_FILE_NAME = 'outputs/movielens_sar_model.pkl'\n",
    "MODEL_FILE_NAME = 'movielens_sar_model.pkl'\n",
    "\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "# let user feed in 2 parameters, the location of the data files (from datastore), and the regularization rate of the logistic regression model\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--data-file', type=str, dest='data_file', help='data file name')\n",
    "parser.add_argument('--top-k', type=int, dest='top_k', default=10, help='top k items to recommend')\n",
    "parser.add_argument('--data-size', type=str, dest='data_size', default=10, help='Movielens data size: 100k, 1m, 10m, or 20m')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# set col names\n",
    "header = {\n",
    "    \"col_user\": \"UserId\",\n",
    "    \"col_item\": \"MovieId\",\n",
    "    \"col_rating\": \"Rating\",\n",
    "    \"col_timestamp\": \"Timestamp\",\n",
    "}\n",
    "\n",
    "# read data\n",
    "data_pickle_path = os.path.join(args.data_folder, args.data_file)\n",
    "data = pd.read_pickle(data_pickle_path)\n",
    "\n",
    "# Log arguments to the run for tracking\n",
    "run.log(\"top-k\", args.top_k)\n",
    "run.log(\"data-size\", args.data_size)\n",
    "\n",
    "# split dataset into train and test\n",
    "train, test = python_stratified_split(data, ratio=0.75, col_user=header[\"col_user\"], col_item=header[\"col_item\"], seed=42)\n",
    "\n",
    "# instantiate the model\n",
    "model = SAR(\n",
    "    similarity_type=\"jaccard\", \n",
    "    time_decay_coefficient=30, \n",
    "    time_now=None, \n",
    "    timedecay_formula=True, \n",
    "    **header\n",
    ")\n",
    "\n",
    "# train the SAR model\n",
    "with Timer() as t:\n",
    "    model.fit(train)\n",
    "\n",
    "run.log(name=\"Training time\", value=t.interval)\n",
    "\n",
    "# predict top k items\n",
    "with Timer() as t:\n",
    "    top_k = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "run.log(name=\"Prediction time\", value=t.interval)\n",
    "\n",
    "# compute evaluation metrics\n",
    "eval_map = map_at_k(test, top_k, col_user=\"UserId\", col_item=\"MovieId\", \n",
    "                    col_rating=\"Rating\", col_prediction=\"prediction\", \n",
    "                    relevancy_method=\"top_k\", k=args.top_k)\n",
    "eval_ndcg = ndcg_at_k(test, top_k, col_user=\"UserId\", col_item=\"MovieId\", \n",
    "                      col_rating=\"Rating\", col_prediction=\"prediction\", \n",
    "                      relevancy_method=\"top_k\", k=args.top_k)\n",
    "eval_precision = precision_at_k(test, top_k, col_user=\"UserId\", col_item=\"MovieId\", \n",
    "                                col_rating=\"Rating\", col_prediction=\"prediction\", \n",
    "                                relevancy_method=\"top_k\", k=args.top_k)\n",
    "eval_recall = recall_at_k(test, top_k, col_user=\"UserId\", col_item=\"MovieId\", \n",
    "                          col_rating=\"Rating\", col_prediction=\"prediction\", \n",
    "                          relevancy_method=\"top_k\", k=args.top_k)\n",
    "\n",
    "run.log(\"map\", eval_map)\n",
    "run.log(\"ndcg\", eval_ndcg)\n",
    "run.log(\"precision\", eval_precision)\n",
    "run.log(\"recall\", eval_recall)\n",
    "\n",
    "# automatic upload of everything in ./output folder doesn't work for very large model file\n",
    "# model file has to be saved to a temp location, then uploaded by upload_file function\n",
    "joblib.dump(value=model, filename=MODEL_FILE_NAME)\n",
    "\n",
    "run.upload_file(OUTPUT_FILE_NAME, MODEL_FILE_NAME)\n",
    "\n",
    "## Register the model, then deploy\n",
    "run.register_model(model_path=OUTPUT_FILE_NAME, model_name=MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpemvzlzed/movielens-sar/recommenders'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy dependent python files\n",
    "UTILS_DIR = os.path.join(SCRIPT_DIR, 'recommenders')\n",
    "if os.path.exists(UTILS_DIR):\n",
    "    shutil.rmtree(UTILS_DIR)\n",
    "shutil.copytree('../../recommenders/', UTILS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training script\n",
    "### 1. Create an estimator\n",
    "An [estimator](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-ml-models) object is used to submit the run. You can create and use a generic Estimator to submit a training script using any learning framework you choose (such as scikit-learn) you want to run on any compute target, whether it's your local machine, a single VM in Azure, or a GPU cluster in Azure. \n",
    "\n",
    "Create your estimator by running the following code to define:  \n",
    "* The name of the estimator object, `est`\n",
    "* The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for execution. \n",
    "* The compute target.  In this case you will use the AzureML Compute you created\n",
    "* The training script name, train.py\n",
    "* Parameters required from the training script \n",
    "* Python packages needed for training\n",
    "* Connect to the data files in the datastore\n",
    "\n",
    "In this tutorial, this target is AzureML Compute. All files in the script folder are uploaded into the cluster nodes for execution. `ds.as_mount()` mounts a datastore on the remote compute and returns the folder. See documentation [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data#access-datastores-during-training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "configure estimator"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.estimator._estimator:'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    }
   ],
   "source": [
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--data-file': 'movielens/' + data_file_name,\n",
    "    '--top-k': TOP_K,\n",
    "    '--data-size': MOVIELENS_DATA_SIZE\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=SCRIPT_DIR,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['pandas'],\n",
    "                pip_packages=['sklearn', 'tqdm', 'recommenders[examples]', 'azureml-mlflow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Submit the job to the cluster\n",
    "An [experiment](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py#experiment) is a logical container in an AzureML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments. We access an experiment from our AzureML workspace by name, which will be created if it doesn't exist.\n",
    "\n",
    "Then, run the experiment by submitting the estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    }
   ],
   "source": [
    "# create experiment\n",
    "EXPERIMENT_NAME = 'movielens-sar'\n",
    "exp = Experiment(workspace=ws, name=EXPERIMENT_NAME)\n",
    "\n",
    "run = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.  Monitor remote run\n",
    "\n",
    "#### Jupyter widget\n",
    "\n",
    "Jupyter widget can watch the progress of the run.  Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6282f9dde6034e198e08e87e446e6ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/movielens-sar_1663214843_7c63a08f?wsid=/subscriptions/b068fa50-ccf9-4b66-88e6-659b8f777d02/resourcegroups/activateazureml-rg/workspaces/activateazureml-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"run_properties\": {\"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"created_utc\": \"2022-09-15T04:07:25.157375Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlctrain\", \"ContentSnapshotId\": \"4a3f3457-840f-4f04-ac81-b2d85fa569a5\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":2}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"train.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-09-15T04:07:57.542868Z\", \"status\": \"Completed\", \"log_files\": {\"user_logs/std_log.txt\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=T849klfBGbD%2Bh9XfiJrQE54vdtA%2Fx9Dj%2FRA16r6EDt8%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/cs_capability/cs-capability.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=MgnqJQ10KvT7YSebyCZYQh%2BXoLqVhRsJd6il0wRo664%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/data_capability/data-capability.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=khqQkTRjRz9d1AMABenkM4VPbLYT1QxS7x9wRgokSy4%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/data_capability/rslex.log.2022-09-15-04\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/data_capability/rslex.log.2022-09-15-04?sv=2019-07-07&sr=b&sig=E3X71%2Fb%2FR65HdddUPS1CYYirNL8LB4jpN7xjPjhxCL0%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/hosttools_capability/hosttools-capability.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=rGvgBXafgfDHfxiOIodJYBgsmTl6Bc4kv8%2F%2FKYCY2Hw%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/lifecycler/execution-wrapper.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=%2FLgfm2aQ2GnvetUj6%2B2rTR6nZkKLX9bNB%2FjtOzdylq0%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/lifecycler/lifecycler.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=9rjJkDiS%2FAI2XCYSeeYGDroak0OhPmvJ%2FRbe5JG41Hk%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/metrics_capability/metrics-capability.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=kgJAc8G6kptCmatMMpq16m5PAxG12S8XiG6SERf5euk%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\", \"system_logs/snapshot_capability/snapshot-capability.log\": \"https://activateazurem4691093227.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens-sar_1663214843_7c63a08f/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=p7CY155ntHDUAecVr0vvr8%2BEGODYWznTnlA%2BxpMA5yo%3D&skoid=1c36debb-71f9-416b-9cac-bed93630ed27&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-09-15T01%3A12%3A41Z&ske=2022-09-16T09%3A22%3A41Z&sks=b&skv=2019-07-07&st=2022-09-15T05%3A13%3A30Z&se=2022-09-15T13%3A23%3A30Z&sp=r\"}, \"log_groups\": [[\"user_logs/std_log.txt\", \"system_logs/cs_capability/cs-capability.log\", \"system_logs/data_capability/data-capability.log\", \"system_logs/hosttools_capability/hosttools-capability.log\", \"system_logs/lifecycler/execution-wrapper.log\", \"system_logs/lifecycler/lifecycler.log\", \"system_logs/metrics_capability/metrics-capability.log\", \"system_logs/snapshot_capability/snapshot-capability.log\"], [\"system_logs/data_capability/rslex.log.2022-09-15-04\"]], \"run_duration\": \"0:00:32\", \"run_number\": \"1663214845\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"top-k\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [10]}]}, {\"name\": \"data-size\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [\"100k\"]}]}, {\"name\": \"Training time\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [0.3741760470002191]}]}, {\"name\": \"Prediction time\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [0.11116992300003403]}]}, {\"name\": \"map\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [0.11059057578638949]}]}, {\"name\": \"ndcg\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [0.3824612290501957]}]}, {\"name\": \"precision\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [0.33075291622481445]}]}, {\"name\": \"recall\", \"run_id\": \"movielens-sar_1663214843_7c63a08f\", \"categories\": [0], \"series\": [{\"data\": [0.1763854474342893]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.45.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Viewing run results\n",
    "Azure Machine Learning stores all the details about the run in the Azure cloud. Let's access those details by retrieving a link to the run using the default run output. Clicking on the resulting link will take you to an interactive page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>movielens-sar</td><td>movielens-sar_1663214843_7c63a08f</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/movielens-sar_1663214843_7c63a08f?wsid=/subscriptions/b068fa50-ccf9-4b66-88e6-659b8f777d02/resourcegroups/activateazureml-rg/workspaces/activateazureml-ws&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: movielens-sar,\n",
       "Id: movielens-sar_1663214843_7c63a08f,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above cell should output similar table as below.\n",
    "\n",
    "![Experiment submit output](https://recodatasets.z20.web.core.windows.net/images/aml_sar_output.jpg)\n",
    "\n",
    "After clicking \"Link to Azure Portal\", experiment run details tab looks like this with logged metrics.\n",
    "\n",
    "![Azure Portal Experiment](https://recodatasets.z20.web.core.windows.net/images/aml_sar_workspace.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top-k': 10,\n",
       " 'data-size': '100k',\n",
       " 'Training time': 0.3741760470002191,\n",
       " 'Prediction time': 0.11116992300003403,\n",
       " 'map': 0.11059057578638949,\n",
       " 'ndcg': 0.3824612290501957,\n",
       " 'precision': 0.33075291622481445,\n",
       " 'recall': 0.1763854474342893}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run below after run is complete, otherwise metrics is empty\n",
    "metrics = run.get_metrics()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movielens_sar_model.pkl version: 2\n",
      "\n",
      "\n",
      "movielens_sar_model.pkl version: 1\n",
      "\n",
      "\n",
      "AutoML7c8a6c67e33 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_20 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_19 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_18 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_17 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_16 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_15 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_14 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_13 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_12 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_11 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_10 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_9 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_8 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_7 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_6 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_5 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_4 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_3 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_2 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_1 version: 1\n",
      "\n",
      "\n",
      "diabetes_unmitigated version: 1\n",
      "\n",
      "\n",
      "diabetes_classifier version: 2\n",
      "\n",
      "\n",
      "diabetes_classifier version: 1\n",
      "\n",
      "\n",
      "RULPredictInitial version: 5\n",
      "\n",
      "\n",
      "RULPredictInitial version: 4\n",
      "\n",
      "\n",
      "amlstudio-automobile-price-pre version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "XgBoostClassification version: 10\n",
      "\t data : Engine Data\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "automl_rai version: 2\n",
      "\n",
      "\n",
      "RULPredictInitial version: 3\n",
      "\n",
      "\n",
      "RULPredictInitial version: 2\n",
      "\n",
      "\n",
      "RULPredictInitial version: 1\n",
      "\n",
      "\n",
      "bidaf-9-tutorial version: 1\n",
      "\t area : Natural language processing\n",
      "\t type : Question-answering\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 10\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 9\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "grid_35 version: 1\n",
      "\n",
      "\n",
      "grid_34 version: 1\n",
      "\n",
      "\n",
      "grid_33 version: 1\n",
      "\n",
      "\n",
      "grid_32 version: 1\n",
      "\n",
      "\n",
      "grid_31 version: 1\n",
      "\n",
      "\n",
      "grid_30 version: 1\n",
      "\n",
      "\n",
      "grid_29 version: 1\n",
      "\n",
      "\n",
      "unmitigated version: 1\n",
      "\n",
      "\n",
      "LogisticRegrModel version: 1\n",
      "\t azureml.datastoreId : /subscriptions/b068fa50-ccf9-4b66-88e6-659b8f777d02/resourceGroups/ActivateAzureML-RG/providers/Microsoft.MachineLearningServices/workspaces/ActivateAzureML-WS/datastores/workspaceartifactstore\n",
      "\n",
      "\n",
      "XgBoostClassification version: 9\n",
      "\t data : Engine Data\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "XgBoostClassification version: 8\n",
      "\n",
      "\n",
      "XgBoostClassification version: 7\n",
      "\n",
      "\n",
      "XgBoostClassification version: 6\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 8\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "XgBoostClassification version: 5\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 7\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "XgBoostClassification version: 4\n",
      "\n",
      "\n",
      "XgBoostClassification version: 3\n",
      "\n",
      "\n",
      "XgBoostClassification version: 2\n",
      "\n",
      "\n",
      "XgBoostClassification version: 1\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 6\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 5\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "automl_rai version: 1\n",
      "\n",
      "\n",
      "inception version: 2\n",
      "\t pretrained : inception\n",
      "\n",
      "\n",
      "inception version: 1\n",
      "\t pretrained : inception\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 4\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "my_second_model version: 4\n",
      "\n",
      "\n",
      "my_first_model version: 4\n",
      "\n",
      "\n",
      "my_second_model version: 3\n",
      "\n",
      "\n",
      "my_first_model version: 3\n",
      "\n",
      "\n",
      "my_second_model version: 2\n",
      "\n",
      "\n",
      "my_first_model version: 2\n",
      "\n",
      "\n",
      "sklearn_regression_model.pkl version: 4\n",
      "\t area : diabetes\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "iris.model version: 2\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "iris.model version: 1\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "my_second_model version: 1\n",
      "\n",
      "\n",
      "my_first_model version: 1\n",
      "\n",
      "\n",
      "sklearn_regression_model.pkl version: 3\n",
      "\t area : diabetes\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "sklearn_regression_model.pkl version: 2\n",
      "\t area : diabetes\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "sklearn_regression_model.pkl version: 1\n",
      "\t area : diabetes\n",
      "\t type : regression\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 3\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 2\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n",
      "RegressionDecisionTree version: 1\n",
      "\t key : 0.1\n",
      "\t name : RUL_DT.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movielens_sar_model.pkl version 2\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['movielens_sar_model.pkl']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model\n",
    "\n",
    "Deploy the model as a web service using the 'Model.deploy()' method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sar_movie_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './sar_movie_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_movies.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sar_movie_service/score_movies.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'movielens_sar_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # top_k = model.recommend_k_items(raw_data, top_k=10, remove_seen=True)\n",
    "    \n",
    "    # Return the predictions as JSON\n",
    "    # return json.dumps(top_k)\n",
    "    return predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = CondaDependencies.create(conda_packages=['sklearn', 'tqdm', 'recommenders[examples]', 'azureml-mlflow'])\n",
    "\n",
    "with open(\"./sar_movie_service/env.yml\", \"w\") as f:\n",
    "    f.write(env.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-09-15 05:13:24+00:00 Creating Container Registry if not exists.\n",
      "2022-09-15 05:13:24+00:00 Registering the environment.\n",
      "2022-09-15 05:13:26+00:00 Building image.\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:azureml.core.webservice.webservice:Service deployment polling reached non-successful terminal state, current service state: Unhealthy\n",
      "Operation ID: 172e9315-0f00-48d3-b004-a5348c1a1f25\n",
      "More information can be found here: https://activateazurem4691093227.blob.core.windows.net/azureml/ImageLogs/172e9315-0f00-48d3-b004-a5348c1a1f25/build.log?sv=2019-07-07&sr=b&sig=FajGkwkbB3swuk6uIfT1cUSWajIz5ResZoGAZia3lnQ%3D&st=2022-09-15T05%3A18%3A42Z&se=2022-09-15T13%3A23%3A42Z&sp=r\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"EnvironmentBuildFailed\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Failed building the Environment. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 172e9315-0f00-48d3-b004-a5348c1a1f25\nMore information can be found here: https://activateazurem4691093227.blob.core.windows.net/azureml/ImageLogs/172e9315-0f00-48d3-b004-a5348c1a1f25/build.log?sv=2019-07-07&sr=b&sig=FajGkwkbB3swuk6uIfT1cUSWajIz5ResZoGAZia3lnQ%3D&st=2022-09-15T05%3A18%3A42Z&se=2022-09-15T13%3A23%3A42Z&sp=r\nError:\n{\n  \"code\": \"EnvironmentBuildFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Failed building the Environment. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: 172e9315-0f00-48d3-b004-a5348c1a1f25\\nMore information can be found here: https://activateazurem4691093227.blob.core.windows.net/azureml/ImageLogs/172e9315-0f00-48d3-b004-a5348c1a1f25/build.log?sv=2019-07-07&sr=b&sig=FajGkwkbB3swuk6uIfT1cUSWajIz5ResZoGAZia3lnQ%3D&st=2022-09-15T05%3A18%3A42Z&se=2022-09-15T13%3A23%3A42Z&sp=r\\nError:\\n{\\n  \\\"code\\\": \\\"EnvironmentBuildFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Failed building the Environment. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m service_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msar-movie-service-alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m service \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mdeploy(ws, service_name, [model], inference_config, deployment_config, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(service\u001b[38;5;241m.\u001b[39mstate)\n",
      "File \u001b[0;32m/anaconda/lib/python3.9/site-packages/azureml/core/webservice/webservice.py:918\u001b[0m, in \u001b[0;36mWebservice.wait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m logs_response:\n\u001b[1;32m    916\u001b[0m             logs_response \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCurrent sub-operation type not known, more logs unavailable.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 918\u001b[0m         \u001b[39mraise\u001b[39;00m WebserviceException(\u001b[39m'\u001b[39m\u001b[39mService deployment polling reached non-successful terminal state, current \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    919\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mservice state: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    920\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mOperation ID: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    921\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    922\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    923\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operation_endpoint\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    924\u001b[0m                                               logs_response, format_error_response), logger\u001b[39m=\u001b[39mmodule_logger)\n\u001b[1;32m    925\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m service creation operation finished, operation \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_webservice_type,\n\u001b[1;32m    926\u001b[0m                                                                           operation_state))\n\u001b[1;32m    927\u001b[0m \u001b[39mexcept\u001b[39;00m WebserviceException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 172e9315-0f00-48d3-b004-a5348c1a1f25\nMore information can be found here: https://activateazurem4691093227.blob.core.windows.net/azureml/ImageLogs/172e9315-0f00-48d3-b004-a5348c1a1f25/build.log?sv=2019-07-07&sr=b&sig=FajGkwkbB3swuk6uIfT1cUSWajIz5ResZoGAZia3lnQ%3D&st=2022-09-15T05%3A18%3A42Z&se=2022-09-15T13%3A23%3A42Z&sp=r\nError:\n{\n  \"code\": \"EnvironmentBuildFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Failed building the Environment. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: 172e9315-0f00-48d3-b004-a5348c1a1f25\\nMore information can be found here: https://activateazurem4691093227.blob.core.windows.net/azureml/ImageLogs/172e9315-0f00-48d3-b004-a5348c1a1f25/build.log?sv=2019-07-07&sr=b&sig=FajGkwkbB3swuk6uIfT1cUSWajIz5ResZoGAZia3lnQ%3D&st=2022-09-15T05%3A18%3A42Z&se=2022-09-15T13%3A23%3A42Z&sp=r\\nError:\\n{\\n  \\\"code\\\": \\\"EnvironmentBuildFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Failed building the Environment. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "# service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")\n",
    "# # service_env.inferencing_stack_version=\"latest\"\n",
    "\n",
    "# inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "#                                    entry_script=script_file,\n",
    "#                                    environment=env)\n",
    "\n",
    "inference_config = InferenceConfig(runtime=\"python\", entry_script=\"./sar_movie_service/score_movies.py\", conda_file=\"./sar_movie_service/env.yml\")\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"sar-movie-service-alpha\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprovision compute resource\n",
    "To avoid unnecessary charges, if you created compute target that doesn't scale down to 0, make sure the compute target is deprovisioned after use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete () is used to deprovision and delete the AzureML Compute target. \n",
    "# do not run below before experiment completes\n",
    "\n",
    "# compute_target.delete()\n",
    "\n",
    "# deletion will take a few minutes. You can check progress in Azure Portal / Computing tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up temporary directory\n",
    "# tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0194299e911b6a22f0cd3d1c9a66c991d39f48b249be23f24104e40900e329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
